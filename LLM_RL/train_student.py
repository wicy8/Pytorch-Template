import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# ================= 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç† =================
print("Loading data...")

# [Pandas]: è¯»å– CSV æ–‡ä»¶
df = pd.read_csv("expert_data.csv")

# æå–ç‰¹å¾ (Input) å’Œ æ ‡ç­¾ (Label)
# ç‰¹å¾æ˜¯æˆ‘ä»¬ç”Ÿæˆçš„ç¯å¢ƒçŠ¶æ€ï¼šä»»åŠ¡å¤§å°, æ—¶å»¶è¦æ±‚, å¸¦å®½, è´Ÿè½½
X_raw = df[['task_size', 'latency_limit', 'bandwidth', 'server_load']].values  # .values æŠŠè¡¨æ ¼å˜æˆäº† Numpy æ•°ç»„
# æ ‡ç­¾æ˜¯è€å¸ˆç»™å‡ºçš„åŠ¨ä½œï¼š0 æˆ– 1
y_raw = df['label_action'].values

# [æ•°æ®æ ‡å‡†åŒ–]: è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼
# å› ä¸º 'ä»»åŠ¡å¤§å°' æ˜¯ 1-50ï¼Œè€Œ 'æ—¶å»¶' æ˜¯ 10-200ã€‚æ•°å€¼èŒƒå›´å·®è·å¤ªå¤§ï¼Œç¥ç»ç½‘ç»œä¼šæ™•ã€‚
# StandardScaler æŠŠå®ƒä»¬éƒ½ç¼©æ”¾åˆ° 0 é™„è¿‘ (å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1)ã€‚
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_raw)

# [Sklearn]: åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# 80% çš„æ•°æ®ç”¨æ¥è®­ç»ƒ(å­¦ä¹ )ï¼Œ20% ç”¨æ¥æµ‹è¯•(è€ƒè¯•)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_raw, test_size=0.2, random_state=42)

# [PyTorch]: æŠŠ Numpy æ•°ç»„å˜æˆ PyTorch èƒ½è®¤è¯†çš„ Tensor (å¼ é‡)
# float32 æ˜¯æ ‡å‡†å°æ•°æ ¼å¼ï¼Œlong æ˜¯æ•´æ•°æ ¼å¼(ç”¨äºåˆ†ç±»æ ‡ç­¾)
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.long)

print(f"æ•°æ®å‡†å¤‡å®Œæ¯•ï¼è®­ç»ƒé›†æ•°é‡: {len(X_train)}, æµ‹è¯•é›†æ•°é‡: {len(X_test)}")


# ================= 2. å®šä¹‰ç¥ç»ç½‘ç»œ (Student Model) =================
class StudentNet(nn.Module):
    def __init__(self):
        super(StudentNet, self).__init__()
        # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ 3 å±‚å…¨è¿æ¥ç½‘ç»œ (MLP)
        # è¾“å…¥å±‚ (4ä¸ªç‰¹å¾) -> éšè—å±‚ (64ä¸ªç¥ç»å…ƒ) -> è¾“å‡ºå±‚ (2ä¸ªåŠ¨ä½œ: 0æˆ–1)
        self.fc1 = nn.Linear(4, 64)
        self.relu = nn.ReLU()  # æ¿€æ´»å‡½æ•° (ç»™ç½‘ç»œä¸€ç‚¹éçº¿æ€§æ€è€ƒèƒ½åŠ›)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 2)  # è¾“å‡º2ä¸ªå€¼ï¼Œåˆ†åˆ«ä»£è¡¨é€‰0å’Œé€‰1çš„â€œå¾—åˆ†â€

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x


# åˆå§‹åŒ–æ¨¡å‹
student_model = StudentNet()
# å®šä¹‰æŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µæŸå¤± (CrossEntropyLoss)ï¼Œä¸“é—¨ç”¨äºåˆ†ç±»ä»»åŠ¡
criterion = nn.CrossEntropyLoss()
# å®šä¹‰ä¼˜åŒ–å™¨ï¼šAdam (ç›®å‰æœ€å¸¸ç”¨çš„ä¼˜åŒ–å™¨)ï¼Œlræ˜¯å­¦ä¹ ç‡
optimizer = optim.Adam(student_model.parameters(), lr=0.01)

# ================= 3. å¼€å§‹è®­ç»ƒ (Training Loop) =================
epochs = 100  # è®­ç»ƒ 100 è½®
losses = []  # ç”¨äºç”»å›¾ï¼Œè®°å½•æ¯ä¸€è½®çš„ Loss

print("\nğŸš€ å¼€å§‹è®­ç»ƒ Student æ¨¡å‹...")

for epoch in range(epochs):
    # --- æ­£å‘ä¼ æ’­ ---
    optimizer.zero_grad()  # æ¢¯åº¦æ¸…é›¶ (æ¯æ¬¡é‡æ–°ç®—)
    outputs = student_model(X_train_tensor)  # å–‚æ•°æ®ï¼Œå¾—ç»“æœ
    loss = criterion(outputs, y_train_tensor)  # ç®—ç®—å’Œæ ‡å‡†ç­”æ¡ˆå·®å¤šå°‘

    # --- åå‘ä¼ æ’­ ---
    loss.backward()  # ç®—å‡ºè¯¯å·®æ€ä¹ˆä¼ å¯¼
    optimizer.step()  # æ›´æ–°ç½‘ç»œå‚æ•°

    losses.append(loss.item())  # è®°å½• Loss

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}")

# ================= 4. è€ƒè¯•ä¸ç”»å›¾ (Result Visualization) =================

# åœ¨æµ‹è¯•é›†ä¸Šè€ƒè¯•
with torch.no_grad():  # è€ƒè¯•æ—¶ä¸éœ€è¦ç®—æ¢¯åº¦
    test_outputs = student_model(X_test_tensor)
    # torch.max è¿”å›æœ€å¤§å€¼çš„ç´¢å¼• (å³ç½‘ç»œè®¤ä¸ºæ¦‚ç‡æœ€å¤§çš„åŠ¨ä½œ)
    _, predicted = torch.max(test_outputs, 1)
    # ç®—å‡ºå‡†ç¡®ç‡
    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)

print(f"\nâœ… è®­ç»ƒç»“æŸï¼")
print(f"ğŸ“ Student æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡: {accuracy * 100:.2f}%")

# ä¿å­˜æ¨¡å‹
torch.save(student_model.state_dict(), "student_model.pth")
print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º student_model.pth")

# [Matplotlib]: ç”»å‡º Loss ä¸‹é™æ›²çº¿
plt.plot(losses)
plt.title('Training Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.show()  # è¿™ä¼šå¼¹å‡ºä¸€ä¸ªçª—å£æ˜¾ç¤ºå›¾ç‰‡