import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler


# ================= 1. æ¨¡å‹å®šä¹‰ (å¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€æ¨¡ä¸€æ ·) =================
# å°±åƒè¯»æ¡£ä¸€æ ·ï¼Œä½ çš„â€œç©ºå£³â€ç»“æ„å¿…é¡»å’Œå­˜æ¡£æ—¶çš„ç»“æ„å®Œå…¨ä¸€è‡´ï¼Œæ‰èƒ½æŠŠå‚æ•°è£…è¿›å»
class StudentNet(nn.Module):
    def __init__(self):
        super(StudentNet, self).__init__()
        self.fc1 = nn.Linear(4, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 2)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x


# ================= 2. å‡†å¤‡â€œå°ºå­â€ (StandardScaler) =================
def get_scaler():
    """
    é‡æ–°åŠ è½½è®­ç»ƒæ•°æ®ï¼Œfit ä¸€é scalerï¼Œç¡®ä¿æ¨ç†æ—¶çš„æ•°æ®ç¼©æ”¾æ¯”ä¾‹å’Œè®­ç»ƒæ—¶ä¸€è‡´ã€‚
    åœ¨å·¥ä¸šç•Œï¼Œé€šå¸¸ä¼šæŠŠ scaler ä¿å­˜ä¸ºæ–‡ä»¶ï¼Œä½†ç§‘ç ”Demoé‡Œè¿™æ ·å†™æœ€å¿«ã€‚
    """
    try:
        df = pd.read_csv("expert_data.csv")
        X = df[['task_size', 'latency_limit', 'bandwidth', 'server_load']].values
        scaler = StandardScaler()
        scaler.fit(X)  # è®°ä½æ•°æ®çš„å‡å€¼å’Œæ–¹å·®
        return scaler
    except FileNotFoundError:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° expert_data.csvï¼Œæ— æ³•æ ¡å‡†æ•°æ®ï¼")
        return None


# ================= 3. æ ¸å¿ƒæ¨ç†å‡½æ•° =================
def predict_decision(model, scaler, task_state, device): # <--- ğŸ”§ å¤šä¼ ä¸€ä¸ª device å‚æ•°
    """
    è¾“å…¥ï¼šä¸€ä¸ªå…·ä½“çš„ä»»åŠ¡çŠ¶æ€ [å¤§å°, æ—¶å»¶, å¸¦å®½, è´Ÿè½½]
    è¾“å‡ºï¼šå†³ç­– (0/1) å’Œ ç½®ä¿¡åº¦
    """
    # 1. åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ (å‘Šè¯‰æ¨¡å‹ï¼šç°åœ¨æ˜¯è€ƒè¯•ï¼Œä¸è¦è¿›è¡Œè®­ç»ƒæ—¶çš„éšæœºæ“ä½œ)
    model.eval()

    # 2. æ•°æ®é¢„å¤„ç†
    # å˜æˆ numpy äºŒç»´æ•°ç»„ (1è¡Œ, 4åˆ—)
    state_array = np.array([task_state])
    # ç”¨ä¹‹å‰çš„å°ºå­è¿›è¡Œæ ‡å‡†åŒ–
    state_scaled = scaler.transform(state_array)
    # å˜æˆ Tensorï¼Œåˆ›å»º Tensor æ—¶ï¼Œç›´æ¥æŠŠå®ƒé€åˆ°å’Œæ¨¡å‹ä¸€æ ·çš„ device ä¸Š
    input_tensor = torch.tensor(state_scaled, dtype=torch.float32).to(device)

    # 3. æ¨ç† (Inference)
    with torch.no_grad():  # âš ï¸ å…³é”®ï¼è€ƒè¯•æ—¶ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œèƒ½çœå†…å­˜å¹¶åŠ é€Ÿ
        outputs = model(input_tensor)

        # ä½¿ç”¨ Softmax æŠŠå¾—åˆ†å˜æˆæ¦‚ç‡ (ç™¾åˆ†æ¯”)
        probabilities = torch.softmax(outputs, dim=1)

        # æ‹¿åˆ°æœ€å¤§æ¦‚ç‡çš„ç´¢å¼• (0 æˆ– 1)
        confidence, predicted_class = torch.max(probabilities, 1)

    return predicted_class.item(), confidence.item()


# ================= 4. ä¸»ç¨‹åº =================
if __name__ == "__main__":
    # A. åŠ è½½æ¨¡å‹ç»“æ„ï¼Œè‡ªåŠ¨æ£€æµ‹è®¾å¤‡ (æœ‰æ˜¾å¡å°±ç”¨æ˜¾å¡ï¼Œæ²¡æ˜¾å¡ç”¨CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ å½“å‰è¿è¡Œè®¾å¤‡: {device}")
    # åŠ è½½æ¨¡å‹ç»“æ„åˆ°è®¾å¤‡
    model = StudentNet().to(device)

    # B. åŠ è½½æ¨¡å‹æƒé‡ (è¯»å– .pth å­˜æ¡£)
    # map_location='cpu' ä¿è¯å³ä½¿ä½ åœ¨æœåŠ¡å™¨è®­ç»ƒ(GPU)ï¼Œå›ç¬”è®°æœ¬(CPU)ä¹Ÿèƒ½è·‘
    try:
        # ğŸ”§ ä¿®å¤è­¦å‘Šï¼šæ·»åŠ  weights_only=True
        # map_location ç¡®ä¿æƒé‡è¢«åŠ è½½åˆ°æ­£ç¡®çš„è®¾å¤‡
        model.load_state_dict(torch.load("student_model.pth", map_location='cpu', weights_only=True))
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å‡†å¤‡è¿›è¡Œæ¨ç†...")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° student_model.pthï¼Œè¯·å…ˆè¿è¡Œä»»åŠ¡äºŒè®­ç»ƒæ¨¡å‹ï¼")
        exit()

    # C. å‡†å¤‡å°ºå­
    scaler = get_scaler()
    if scaler is None:
        print("scaler ç”Ÿæˆå¤±è´¥")
        exit()

    print("-" * 50)
    print("ğŸ¤– Edge-LLM-Student è¾¹ç¼˜è°ƒåº¦ç³»ç»Ÿå·²å¯åŠ¨")
    print("-" * 50)

    # D. æ¨¡æ‹Ÿå‡ ä¸ªæ–°ä»»åŠ¡åœºæ™¯
    test_cases = [
        # æ ¼å¼: [ä»»åŠ¡å¤§å°(MB), æ—¶å»¶è¦æ±‚(ms), å¸¦å®½(Mbps), è´Ÿè½½(%)]
        [15.0, 50.0, 80.0, 20.0],  # Case 1: ä»»åŠ¡å°ï¼Œç½‘å¥½ï¼Œè´Ÿè½½ä½ -> åº”è¯¥å¸è½½ (1)
        [45.0, 20.0, 5.0, 90.0],  # Case 2: ä»»åŠ¡å·¨å¤§ï¼Œç½‘çƒ‚ï¼Œè´Ÿè½½é«˜ -> å¿…é¡»æœ¬åœ°å¤„ç†/ä¸¢å¼ƒ (0)
        [10.0, 200.0, 50.0, 50.0],  # Case 3: ä¸­è§„ä¸­çŸ© -> çœ‹æ¨¡å‹åˆ¤æ–­
        [16.0, 200.0, 50.0, 50.0]   # Case 4: æé™ä½ç½® -> æ ¹æ®Case 3æ¢ç´¢æ¨¡å‹åˆ¤æ–­çš„è¾¹ç•Œå€¼
    ]

    labels = {0: "æœ¬åœ°å¤„ç† (Local)", 1: "å¸è½½åˆ°è¾¹ç¼˜ (Edge)"}

    for i, state in enumerate(test_cases):
        action, conf = predict_decision(model, scaler, state, device)

        print(f"\nğŸ“ ä»»åŠ¡ {i + 1}: å¤§å°={state[0]}MB, æ—¶å»¶={state[1]}ms, å¸¦å®½={state[2]}Mbps, è´Ÿè½½={state[3]}%")
        print(f"ğŸ§  æ¨¡å‹å†³ç­–: ã€{labels[action]}ã€‘")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {conf * 100:.2f}%")  # çœ‹çœ‹æ¨¡å‹æœ‰å¤šç¡®å®š